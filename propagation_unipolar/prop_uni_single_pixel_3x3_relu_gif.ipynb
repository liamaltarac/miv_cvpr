{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_32715/3418332839.py:5: UserWarning: A NumPy version >=1.23.5 and <2.5.0 is required for this version of SciPy (detected version 1.23.0)\n",
      "  from scipy import ndimage\n",
      "2025-12-01 13:56:22.275931: I tensorflow/core/util/port.cc:113] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2025-12-01 13:56:22.442387: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2025-12-01 13:56:22.442461: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2025-12-01 13:56:22.467045: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2025-12-01 13:56:22.520233: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX512F AVX512_VNNI AVX512_BF16 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2025-12-01 13:56:23.048493: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "sys.path.append('../')\n",
    "\n",
    "import numpy as np\n",
    "from scipy import ndimage\n",
    "\n",
    "from skimage.filters import sobel_h\n",
    "from skimage.filters import sobel_v\n",
    "from scipy import stats\n",
    "\n",
    "\n",
    "import os\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "from mpl_toolkits.mplot3d.proj3d import proj_transform\n",
    "from matplotlib.patches import FancyArrowPatch\n",
    "from mpl_toolkits.mplot3d import proj3d\n",
    "\n",
    "\n",
    "import scienceplots\n",
    "from tensorflow.python.client import device_lib\n",
    "\n",
    "#plt.rcParams['figure.figsize'] = [10,10]\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing import image\n",
    "from tensorflow.keras.applications.vgg16 import decode_predictions\n",
    "from tensorflow.keras.applications import VGG16\n",
    "\n",
    "from tensorflow.nn import depthwise_conv2d\n",
    "from tensorflow.math import multiply, reduce_sum, reduce_mean,reduce_euclidean_norm, sin, cos, abs\n",
    "from tensorflow import stack, concat, expand_dims\n",
    "\n",
    "import tensorflow_probability as tfp\n",
    "\n",
    "from utils.utils import *\n",
    "import cv2\n",
    "\n",
    "from scipy import ndimage, fft\n",
    "from io import BytesIO\n",
    "\n",
    "import imageio.v2 as imageio\n",
    "\n",
    "plt.style.use(['science', 'ieee'])\n",
    "plt.rcParams.update({'figure.dpi': '100'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "k = 3   # kernel size\n",
    "beta2s = [1, 0, 0.25, 0.5, 0.75] #[0, 0.25, 0.75, 1]  \n",
    "activations = [tf.nn.relu]\n",
    "timestamps = [1,5,10]\n",
    "experiment_name = \"unipolar_single_pixel\"\n",
    "box_dims = [20, 16]\n",
    "step =   2 # Plot axis step"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'relu'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.nn.relu.__name__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(115, 115)\n"
     ]
    }
   ],
   "source": [
    "# Single pixel input\n",
    "\n",
    "img = np.zeros((115,115)) # cv2.imread('input4.png', 0)/255. \n",
    "mid = img.shape[0]//2\n",
    "img[mid, mid] = 1.\n",
    "print(img.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-12-01 13:56:24.181186: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:901] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2025-12-01 13:56:24.349316: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:901] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2025-12-01 13:56:24.350652: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:901] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2025-12-01 13:56:24.351793: W tensorflow/core/common_runtime/gpu/gpu_device.cc:2348] TensorFlow was not built with CUDA kernel binaries compatible with compute capability 12.0. CUDA kernels will be jit-compiled from PTX, which could take 30 minutes or longer.\n",
      "2025-12-01 13:56:24.352797: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:901] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2025-12-01 13:56:24.354037: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:901] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2025-12-01 13:56:24.355186: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:901] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2025-12-01 13:56:24.356322: W tensorflow/core/common_runtime/gpu/gpu_device.cc:2348] TensorFlow was not built with CUDA kernel binaries compatible with compute capability 12.0. CUDA kernels will be jit-compiled from PTX, which could take 30 minutes or longer.\n",
      "2025-12-01 13:56:24.468062: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:901] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2025-12-01 13:56:24.468934: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:901] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2025-12-01 13:56:24.469630: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:901] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2025-12-01 13:56:24.470356: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1929] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 8732 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 5070, pci bus id: 0000:01:00.0, compute capability: 12.0\n"
     ]
    }
   ],
   "source": [
    "filters = np.zeros((3,3,1,1))\n",
    "img = tf.cast(tf.repeat(tf.expand_dims([img], axis=-1) , repeats = filters.shape[-2], axis=-1), dtype=tf.float32) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-12-01 13:56:24.659252: I external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:454] Loaded cuDNN version 8907\n",
      "2025-12-01 13:56:24.747316: E external/local_xla/xla/stream_executor/gpu/asm_compiler.cc:115] *** WARNING *** You are using ptxas 10.1.243, which is older than 11.1. ptxas before 11.1 is known to miscompile XLA code, leading to incorrect results or invalid-address errors.\n",
      "\n",
      "2025-12-01 13:56:24.748962: W external/local_xla/xla/stream_executor/gpu/asm_compiler.cc:225] Falling back to the CUDA driver for PTX compilation; ptxas does not support CC 12.0\n",
      "2025-12-01 13:56:24.748973: W external/local_xla/xla/stream_executor/gpu/asm_compiler.cc:228] Used ptxas at ptxas\n",
      "2025-12-01 13:56:24.749023: W external/local_xla/xla/stream_executor/gpu/redzone_allocator.cc:322] UNIMPLEMENTED: ptxas ptxas too old. Falling back to the driver to compile.\n",
      "Relying on driver to perform ptx compilation. \n",
      "Modify $PATH to customize ptxas location.\n",
      "This message will be only logged once.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8 -8\n",
      "1 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-12-01 13:56:24.981818: E external/local_xla/xla/stream_executor/gpu/asm_compiler.cc:115] *** WARNING *** You are using ptxas 10.1.243, which is older than 11.1. ptxas before 11.1 is known to miscompile XLA code, leading to incorrect results or invalid-address errors.\n",
      "\n",
      "2025-12-01 13:56:24.983292: W tensorflow/compiler/mlir/tools/kernel_gen/transforms/gpu_kernel_to_blob_pass.cc:191] Failed to compile generated PTX with ptxas. Falling back to compilation by driver.\n",
      "2025-12-01 13:56:25.063158: E external/local_xla/xla/stream_executor/gpu/asm_compiler.cc:115] *** WARNING *** You are using ptxas 10.1.243, which is older than 11.1. ptxas before 11.1 is known to miscompile XLA code, leading to incorrect results or invalid-address errors.\n",
      "\n",
      "2025-12-01 13:56:25.064356: W tensorflow/compiler/mlir/tools/kernel_gen/transforms/gpu_kernel_to_blob_pass.cc:191] Failed to compile generated PTX with ptxas. Falling back to compilation by driver.\n",
      "2025-12-01 13:56:25.065068: E external/local_xla/xla/stream_executor/gpu/asm_compiler.cc:115] *** WARNING *** You are using ptxas 10.1.243, which is older than 11.1. ptxas before 11.1 is known to miscompile XLA code, leading to incorrect results or invalid-address errors.\n",
      "\n",
      "2025-12-01 13:56:25.065902: E external/local_xla/xla/stream_executor/gpu/asm_compiler.cc:115] *** WARNING *** You are using ptxas 10.1.243, which is older than 11.1. ptxas before 11.1 is known to miscompile XLA code, leading to incorrect results or invalid-address errors.\n",
      "\n",
      "2025-12-01 13:56:25.066009: W tensorflow/compiler/mlir/tools/kernel_gen/transforms/gpu_kernel_to_blob_pass.cc:191] Failed to compile generated PTX with ptxas. Falling back to compilation by driver.\n",
      "2025-12-01 13:56:25.066469: E external/local_xla/xla/stream_executor/gpu/asm_compiler.cc:115] *** WARNING *** You are using ptxas 10.1.243, which is older than 11.1. ptxas before 11.1 is known to miscompile XLA code, leading to incorrect results or invalid-address errors.\n",
      "\n",
      "2025-12-01 13:56:25.066788: E external/local_xla/xla/stream_executor/gpu/asm_compiler.cc:115] *** WARNING *** You are using ptxas 10.1.243, which is older than 11.1. ptxas before 11.1 is known to miscompile XLA code, leading to incorrect results or invalid-address errors.\n",
      "\n",
      "2025-12-01 13:56:25.066809: E external/local_xla/xla/stream_executor/gpu/asm_compiler.cc:115] *** WARNING *** You are using ptxas 10.1.243, which is older than 11.1. ptxas before 11.1 is known to miscompile XLA code, leading to incorrect results or invalid-address errors.\n",
      "\n",
      "2025-12-01 13:56:25.066867: W tensorflow/compiler/mlir/tools/kernel_gen/transforms/gpu_kernel_to_blob_pass.cc:191] Failed to compile generated PTX with ptxas. Falling back to compilation by driver.\n",
      "2025-12-01 13:56:25.067577: W tensorflow/compiler/mlir/tools/kernel_gen/transforms/gpu_kernel_to_blob_pass.cc:191] Failed to compile generated PTX with ptxas. Falling back to compilation by driver.\n",
      "2025-12-01 13:56:25.067671: E external/local_xla/xla/stream_executor/gpu/asm_compiler.cc:115] *** WARNING *** You are using ptxas 10.1.243, which is older than 11.1. ptxas before 11.1 is known to miscompile XLA code, leading to incorrect results or invalid-address errors.\n",
      "\n",
      "2025-12-01 13:56:25.067685: E external/local_xla/xla/stream_executor/gpu/asm_compiler.cc:115] *** WARNING *** You are using ptxas 10.1.243, which is older than 11.1. ptxas before 11.1 is known to miscompile XLA code, leading to incorrect results or invalid-address errors.\n",
      "\n",
      "2025-12-01 13:56:25.067742: W tensorflow/compiler/mlir/tools/kernel_gen/transforms/gpu_kernel_to_blob_pass.cc:191] Failed to compile generated PTX with ptxas. Falling back to compilation by driver.\n",
      "2025-12-01 13:56:25.067769: W tensorflow/compiler/mlir/tools/kernel_gen/transforms/gpu_kernel_to_blob_pass.cc:191] Failed to compile generated PTX with ptxas. Falling back to compilation by driver.\n",
      "2025-12-01 13:56:25.068653: W tensorflow/compiler/mlir/tools/kernel_gen/transforms/gpu_kernel_to_blob_pass.cc:191] Failed to compile generated PTX with ptxas. Falling back to compilation by driver.\n",
      "2025-12-01 13:56:25.068664: W tensorflow/compiler/mlir/tools/kernel_gen/transforms/gpu_kernel_to_blob_pass.cc:191] Failed to compile generated PTX with ptxas. Falling back to compilation by driver.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved GIF to figures/unipolar_single_pixel_relu_3x3/unipolar_single_pixel_3x3__relu_1.gif\n",
      "Saved GIF to figures/unipolar_single_pixel_relu_3x3/unipolar_single_pixel_3x3__relu_0.gif\n",
      "Saved GIF to figures/unipolar_single_pixel_relu_3x3/unipolar_single_pixel_3x3__relu_0.25.gif\n",
      "Saved GIF to figures/unipolar_single_pixel_relu_3x3/unipolar_single_pixel_3x3__relu_0.5.gif\n",
      "Saved GIF to figures/unipolar_single_pixel_relu_3x3/unipolar_single_pixel_3x3__relu_0.75.gif\n"
     ]
    }
   ],
   "source": [
    "import matplotlib.patches as mpatches\n",
    "\n",
    "\n",
    "\n",
    "filters = np.zeros((3,3,1,1))\n",
    "x = tf.cast(tf.repeat(tf.expand_dims([img], axis=-1) , repeats = filters.shape[-2], axis=-1), dtype=tf.float32) \n",
    "\n",
    "\n",
    "\n",
    "#Get image height and width\n",
    "\n",
    "vals_x = img[0, img.shape[1]//2, :, :]\n",
    "vals_y = img[0, :, img.shape[2]//2, :]\n",
    "nonzeros = np.nonzero(vals_x)[0]\n",
    "if nonzeros.size > 0:\n",
    "    length_y = nonzeros[-1] - nonzeros[0] + 1\n",
    "else:\n",
    "    length_y = 0  # all zeros\n",
    "nonzeros = np.nonzero(vals_x)[0]\n",
    "if nonzeros.size > 0:\n",
    "    length_x = nonzeros[-1] - nonzeros[0] + 1\n",
    "else:\n",
    "    length_x = 0  # all zeros\n",
    "\n",
    "\n",
    "\n",
    "#step = 2**np.floor(np.log2(( (length_x) + np.max(timestamps) )// 5))\n",
    "\n",
    "\n",
    "max_x = int(box_dims[0]*(.7))\n",
    "min_x = -int(box_dims[0]*(.3))\n",
    "\n",
    "max_y = box_dims[1]//2\n",
    "min_y = -(box_dims[1]//2)\n",
    "\n",
    "print(max_y, min_y)\n",
    "print(length_x, length_y)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "for activation in activations:\n",
    "    directory = f\"figures/{experiment_name}_{activation.__name__}_{k}x{k}\"\n",
    "    if not os.path.exists(directory):\n",
    "        os.makedirs(directory)\n",
    "    for beta2 in beta2s:\n",
    "\n",
    "        # list of frames (as numpy arrays) for the GIF\n",
    "        frames = []\n",
    "\n",
    "        filters = np.zeros((3,3,1,1))\n",
    "\n",
    "        t = np.zeros((3,3))\n",
    "        t[1, 0] = np.sqrt(beta2)\n",
    "        t[0, 0] = np.sqrt(1-beta2)\n",
    "        filters = np.reshape(fft.idctn(t, norm='ortho'), (3,3,1,1)) \n",
    "\n",
    "        w = tf.cast(filters, dtype=tf.float32)\n",
    "        w = tf.transpose(w, perm=(1,0,2,3))\n",
    "\n",
    "        x = img  # starting image\n",
    "\n",
    "        # evolve over time\n",
    "        for i in range(timestamps[-1] + 1):\n",
    "            x = x / np.std(x)\n",
    "\n",
    "            if i in timestamps:\n",
    "                # --- create a single-frame figure ---\n",
    "                fig, ax = plt.subplots(figsize=(6, 6))\n",
    "\n",
    "                vals = x[0, x.shape[1]//2, :, :]\n",
    "                vals = vals / np.sum(vals)\n",
    "\n",
    "                pos = np.expand_dims(\n",
    "                    np.linspace(-(x.shape[1]//2), x.shape[1]//2, x.shape[1]),\n",
    "                    -1\n",
    "                )\n",
    "                mean = tf.reduce_sum(pos * vals)\n",
    "                var = tf.reduce_sum(((pos - mean)**2) * vals)\n",
    "                std = np.sqrt(var)\n",
    "\n",
    "                im = ax.imshow(np.sum(x[0, :, :, :], axis=-1))\n",
    "                ax.plot(mid, mid, marker='+', color='red')\n",
    "\n",
    "                ax.annotate(r'$\\sigma_x=$' + f\"{std:.2f}\",\n",
    "                            (0.05, 0.01), ha='left', va='bottom',\n",
    "                            color='white', xycoords='axes fraction', fontsize=20)\n",
    "                ax.annotate(r'$\\mu_x=$' + f\"{mean:.2f}\",\n",
    "                            (0.05, 0.11), ha='left', va='bottom',\n",
    "                            color='white', xycoords='axes fraction', fontsize=20)\n",
    "\n",
    "                ax.set(\n",
    "                    xlim=((mid + min_x, mid + max_x)),\n",
    "                    ylim=((mid + min_y, mid + max_y))\n",
    "                )\n",
    "\n",
    "                # custom ticks\n",
    "                xticks = np.arange(\n",
    "                    np.sign(min_x) * (np.abs(min_x)//2) * 2,\n",
    "                    step + (max_x//2) * 2,\n",
    "                    step=step\n",
    "                ) + mid\n",
    "                yticks = np.arange(\n",
    "                    np.sign(min_y) * (np.abs(min_y)//2) * 2,\n",
    "                    step + (max_y//2) * 2,\n",
    "                    step=step\n",
    "                ) + mid\n",
    "\n",
    "                ax.set_xticks(xticks)\n",
    "                ax.set_yticks(yticks)\n",
    "                ax.tick_params(axis='x', labelsize=15)\n",
    "                ax.tick_params(axis='y', labelsize=15)\n",
    "\n",
    "                ax.set_xticklabels([x_tick - mid for x_tick in xticks])\n",
    "                ax.set_yticklabels([y_tick - mid for y_tick in yticks])\n",
    "\n",
    "                if beta2 == 0:\n",
    "                    ax.set_title(f\"t = {i}\", fontsize=25)\n",
    "\n",
    "                fig.tight_layout()\n",
    "\n",
    "                # ---- capture this frame into memory ----\n",
    "                buf = BytesIO()\n",
    "                fig.savefig(buf, format=\"png\", dpi=fig.dpi, bbox_inches=\"tight\")\n",
    "                buf.seek(0)\n",
    "                frame = imageio.imread(buf)\n",
    "                frames.append(frame)\n",
    "\n",
    "                plt.close(fig)\n",
    "\n",
    "            # update x for next timestep\n",
    "            x = activation(tf.nn.conv2d(x, w, strides=(1, 1), padding='SAME'))\n",
    "\n",
    "        # ----- write the GIF for this (activation, beta2) -----\n",
    "        gif_path = os.path.join(\n",
    "            directory,\n",
    "            f\"{experiment_name}_{k}x{k}__{activation.__name__}_{beta2}.gif\"\n",
    "        )\n",
    "        imageio.mimsave(gif_path, frames, duration=0.3)  # duration = sec/frame\n",
    "        print(f\"Saved GIF to {gif_path}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "i"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "step"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "lam",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
